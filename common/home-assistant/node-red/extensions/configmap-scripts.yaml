---
apiVersion: v1
kind: ConfigMap
metadata:
  name: node-red-scripts
data:
  backup_restore.sh: |
    #!/bin/sh
    set -euo pipefail

    #region global configuration
    URL="http://home-assistant-node-red:1880"
    S3_ASSETS_BUCKET_BACKUP_PATH="$${S3_ASSETS_BUCKET}/$${S3_ASSETS_BUCKET_PATH}/node-red"
    #endregion

    #region functions
    function token() {
      echo "retrieving JWT token..."

      # get JWT token
      basic_auth=`echo -n "$${OIDC_USERNAME}:$${OIDC_AUTH_TOKEN}" | base64 -w0`
      JWT_TOKEN=$(curl -s -X POST $${OIDC_TOKEN_URL} -H "Content-Type: application/x-www-form-urlencoded" -H "Authorization: Basic $${basic_auth}" -d grant_type=client_credentials -d scope="openid profile email urn:zitadel:iam:org:project:id:$${NODE_RED_OIDC_AUDIENCE}:aud" | jq -c '.access_token' -r)
    }

    function check() {
      echo "checking for data..."

      # check for data
      token
      set +e
      homelab-node-red-backup check -e $${URL} -jwt "$${JWT_TOKEN}" 2> /dev/null
      if [[ $? -eq 0 ]]; then
        DATA_EXISTS="true"
      else
        DATA_EXISTS="false"
      fi
      set -e

      echo "evaluated data exists: $${DATA_EXISTS}"
    }

    function backup() {
      echo "backing up..."

      # create backup
      token
      homelab-node-red-backup backup -e $${URL} -jwt "$${JWT_TOKEN}" -f backup.json

      # upload backup to S3
      s3cmd --access_key=$${GCS_ACCESS_KEY_ID} --secret_key="$${GCS_SECRET_ACCESS_KEY}" --host="https://storage.googleapis.com" --host-bucket="https://storage.googleapis.com" sync backup.json s3://$${S3_ASSETS_BUCKET_BACKUP_PATH}/
      s3cmd --access_key=$${SCW_ACCESS_KEY} --secret_key="$${SCW_SECRET_KEY}" --host="https://s3.$${SCW_DEFAULT_REGION}.scw.cloud" --host-bucket="https://%(bucket)s.s3.$${SCW_DEFAULT_REGION}.scw.cloud" sync backup.json s3://$${S3_ASSETS_BUCKET_BACKUP_PATH}/

      echo "backed up and uploaded to s3://$${S3_ASSETS_BUCKET_BACKUP_PATH}/backup.json."
    }

    function restore() {
      echo "restoring from s3://$${S3_ASSETS_BUCKET_BACKUP_PATH}/backup.json..."

      # download backup from S3
      s3cmd --access_key=$${GCS_ACCESS_KEY_ID} --secret_key="$${GCS_SECRET_ACCESS_KEY}" --host="https://storage.googleapis.com" --host-bucket="https://storage.googleapis.com" --recursive --force get s3://$${S3_ASSETS_BUCKET_BACKUP_PATH}/backup.json ./
      s3cmd --access_key=$${SCW_ACCESS_KEY} --secret_key="$${SCW_SECRET_KEY}" --host="https://s3.$${SCW_DEFAULT_REGION}.scw.cloud" --host-bucket="https://%(bucket)s.s3.$${SCW_DEFAULT_REGION}.scw.cloud" --recursive --force get s3://$${S3_ASSETS_BUCKET_BACKUP_PATH}/backup.json ./

      # restore backup
      token
      homelab-node-red-backup restore -e $${URL} -jwt "$${JWT_TOKEN}" -f backup.json
    }
    #endregion

    #region install packages
    apk --no-cache add jq curl s3cmd
    pip install homelab-node-red-backup
    #endregion

    #region log configuration
    echo "using endpoint: $${URL}"
    echo "using S3 bucket and path: $${S3_ASSETS_BUCKET_BACKUP_PATH}"
    #endregion

    #region wait for API readiness
    echo "waiting for API readiness..."
    while [[ ! `curl -s $${URL} -H "Accept: application/json"` ]]; do
      sleep 1
    done
    echo "API is ready."
    #endregion

    #region data check
    check
    #endregion

    #region backup or restore
    # if check returns true, we need to perform a backup
    # otherwise, we have a new (empty) setup and can restore
    if [[ "$${DATA_EXISTS}" == "true" ]]; then
      backup
    else
      restore
    fi
    #endregion
