---
# yaml-language-server: $schema=https://raw.githubusercontent.com/bjw-s/helm-charts/common-3.3.0/charts/library/common/values.schema.json
controllers:
  main:
    type: deployment
    pod:
      runtimeClassName: nvidia
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
    containers:
      faster-whisper:
        image:
          repository: quay.io/linuxserver.io/faster-whisper
          pullPolicy: IfNotPresent
          tag: 2.0.0-gpu

        env:
          - name: NVIDIA_DRIVER_CAPABILITIES
            value: compute,utility
          - name: NVIDIA_VISIBLE_DEVICES
            value: all
          - name: WHISPER_MODEL
            value: base-int8
          - name: WHISPER_LANG
            value: en
          - name: WHISPER_BEAM
            value: "1"

        resources:
          requests:
            cpu: 100m
            memory: 768Mi
            nvidia.com/gpu: "1"
          limits:
            cpu: "1"
            memory: 2048Mi
            nvidia.com/gpu: "1"

        probes:
          liveness:
            enabled: true
          readiness:
            enabled: true
          startup:
            enabled: true
            spec:
              failureThreshold: 30
              periodSeconds: 5

serviceAccount:
  create: true

defaultPodOptions:
  automountServiceAccountToken: false

service:
  faster-whisper:
    controller: main
    enabled: true
    type: LoadBalancer
    ipFamilyPolicy: PreferDualStack
    annotations:
      metallb.universe.tf/loadBalancerIPs: "10.0.73.20,2a01:aea0:dd3:25a:1000:3:4:20"
      external-dns.alpha.kubernetes.io/provider: internal
      external-dns.alpha.kubernetes.io/hostname: whisper.iot.internal.muehlbachler.io
    ports:
      http:
        port: 10300
        targetPort: 10300
